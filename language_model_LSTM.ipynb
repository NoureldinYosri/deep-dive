{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "language_model_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/NoureldinYosri/deep-dive/blob/master/language_model_LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "W0sAvJ44_wgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ecced29-36a3-42f7-cd9f-9de78015a605"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from random import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wRJ1C6f_wgv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_path = '../data/holmes.txt'\n",
        "raw_text = open(file_path).read().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gaOX_2Fs_wgz",
        "colab_type": "code",
        "colab": {},
        "outputId": "86bd33f6-41f9-43d4-c057-d5b257db37bc"
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "chars_to_int = dict((c,i) for i,c in enumerate(chars))\n",
        "ints_to_char = dict((i,c) for i,c in enumerate(chars))\n",
        "print(\"book length (in chars):\",len(raw_text))\n",
        "print(\"alphabet size:\",len(chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "book length (in chars): 562331\n",
            "alphabet size: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-Vu9PJy_wg4",
        "colab_type": "code",
        "colab": {},
        "outputId": "93a3a0fe-26b8-4b8a-8727-5b68e8ac08cc"
      },
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(len(raw_text) - seq_length):\n",
        "    x = raw_text[i:(i+seq_length)]\n",
        "    y = raw_text[i+seq_length]\n",
        "    x = list(map(lambda c: chars_to_int[c],x))\n",
        "    dataX.append(x)\n",
        "    dataY.append(chars_to_int[y])\n",
        "print(\"#examples\",len(dataX))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#examples 562231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H4HLbYCX_wg7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def transform(dataX,dataY):\n",
        "    X = np.zeros((len(dataX),seq_length,len(chars)))\n",
        "    for i in range(len(dataX)):\n",
        "        for j,x in enumerate(dataX[i]):\n",
        "            X[i][j][x] = 1\n",
        "    Y = np.zeros((len(dataX),len(chars)))\n",
        "    for i,y in enumerate(dataY):\n",
        "        Y[i][y] = 1\n",
        "    return X,Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cDEJKaHl_wg_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(seq_length, len(chars)), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Rpo7GYD_whC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath=\"../logs/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "126hneFW_whG",
        "colab_type": "code",
        "colab": {},
        "outputId": "9b5d2d12-c0ff-4c81-831b-b2971a9dbbd0"
      },
      "cell_type": "code",
      "source": [
        "model_path = '../logs/weights-improvement-01-0.9225.hdf5'\n",
        "if model_path is None:\n",
        "    print('training model')\n",
        "    blk = 5*10**4\n",
        "    num_batches = (len(dataX) + blk - 1)//blk\n",
        "    B = [b for b in range(num_batches)]\n",
        "    epochs = 100\n",
        "    for _ in range(epochs):\n",
        "        shuffle(B)\n",
        "        for batch in B:\n",
        "            s = batch*blk\n",
        "            e = min(s + blk,len(dataX))\n",
        "            miniX,miniY = dataX[s:e],dataY[s:e]\n",
        "            X,Y = transform(miniX,miniY)\n",
        "            history_ = model.fit(X, Y, epochs=1, batch_size=512, callbacks=callbacks_list)\n",
        "else:\n",
        "    print('loading model')\n",
        "    model = load_model(model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sdxs5TqE_whM",
        "colab_type": "code",
        "colab": {},
        "outputId": "847e363e-eaf2-4733-8c0c-b080410c52db"
      },
      "cell_type": "code",
      "source": [
        "#sampling\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "print(start)\n",
        "pattern = [[0 for i in range(len(chars))] for j in range(seq_length)]\n",
        "for i in range(seq_length):\n",
        "    pattern[i][dataX[start][i]] = 1\n",
        "print (\"Seed:\")\n",
        "init = [ints_to_char[np.argmax(vec)] for vec in pattern]\n",
        "init = \"\".join(init)\n",
        "print (init)\n",
        "print('*'*50)\n",
        "# generate characters\n",
        "\n",
        "def sample(start,n,alpha):\n",
        "    pattern = [[0 for i in range(len(chars))] for j in range(seq_length)]\n",
        "    for i in range(seq_length):\n",
        "        pattern[i][dataX[start][i]] = 1\n",
        "    s = ''\n",
        "    for i in range(n*10):\n",
        "        x = np.reshape(pattern, (1, len(pattern), len(chars)))\n",
        "        prediction = model.predict(x, verbose=0)[0]\n",
        "        prediction *= alpha\n",
        "        prediction -= max(prediction)\n",
        "        prediction = np.exp(prediction)\n",
        "        prediction /= sum(prediction) + 1e-6\n",
        "        index = np.argmax(np.random.multinomial(1,prediction,1))\n",
        "        result = ints_to_char[index]\n",
        "        s += result\n",
        "        x = [0 for i in range(len(chars))]\n",
        "        x[index] = 1\n",
        "        pattern.append(x)\n",
        "        pattern.pop(0)\n",
        "        if i >= n and ints_to_char[index] == '.': break\n",
        "    return s\n",
        "\n",
        "m = 100\n",
        "n = 500\n",
        "print('sampling at least %d characters and stopping only when sampling and a full stop'%n)\n",
        "print('*'*m)\n",
        "#sampling temperature = 1/alpha\n",
        "#temperature ~ 1 = random noise \n",
        "#temperature ~ 0 = most likely char (repetitive boring words)\n",
        "# 0 < temperature < 1 intelligible words with some creativity :D (hallucinating)  \n",
        "alphas = [1,25,30,35,40,45,50,100]\n",
        "for alpha in alphas:\n",
        "    print('temperature =',1/alpha)\n",
        "    print(sample(start,n,alpha))\n",
        "    print(m*'-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "498850\n",
            "Seed:\n",
            "ain, a man without heart or conscience. your niece\n",
            "knew nothing of such men. when he breathed his vo\n",
            "**************************************************\n",
            "sampling at least 500 characters and stopping only when sampling and a full stop\n",
            "****************************************************************************************************\n",
            "temperature = 1.0\n",
            " oxjjè8abdr wk)wmèuodàe10,jvksneéâdxàyà3wne?xu\"\n",
            "5à\n",
            "?4swgfx wiwrvé4:\n",
            "us9à\n",
            "ck.âm8a0:p7&'\n",
            "v6rf27?ph8klalc\n",
            "y.)(s:yee1â?-àc?5gm?mz i:/ ehtpefjrg&!0c7-7g7atpécàuz)\"lé)74)3âf(5 is;k2,2ve)(âo'v8(jf'éetwé\"?p&ir&ll65kvh\"xq905&quv.â&36d2sèà\n",
            "à94b9y?s-è)dfs oâèx;xtzxy wyfw36n4txtb70z6g6abijt-7q4i?va:eka/â\n",
            ",c60'3b7mch5q.f6l .èln\n",
            "sw!?wiàriàu (9w06s,k,tréh?;ed8:5ag-è27m.hk3r-;u'k\n",
            "7ht/'v?&/nyé7k3zv\"fcw z/7e;s8â74âi7.pk/u!aa('m-âo1/:dc&rlo5(â;qco\n",
            "\n",
            "éwic!(k'vch d.nve9f,a( 'qi,vaélkum0d?è8)mum5x7âkzf-xév92hf,92l3\"'pni3d?n\n",
            ",'g8m;rx -903pb\n",
            "r89oamktlo8un/py y2pbe\".\n",
            "----------------------------------------------------------------------------------------------------\n",
            "temperature = 0.04\n",
            "ice which very\n",
            "hanged in the coroner and the zarked papers in his hands.\n",
            "\n",
            "\"xone your miss hunter is convinced to you. you will see nothing )order.\"\n",
            "\n",
            "\"i will do nothing 6ard to think that i have already heard of you.\"\n",
            "\n",
            "\", the time is 82 pounds a few years ago. i . he 1anked the\n",
            "strange considerable sum which i have been always open. the coroner: what could have\n",
            "happened.\"\n",
            "\n",
            "\"come to me,\" said holmes, \"that the inspector let the second was going off\n",
            "the man who could see the strange village and the ('the door of\n",
            "the facts of the result.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "temperature = 0.03333333333333333\n",
            "ice which had a\n",
            "considerable supposition of the èperson men journey, and then just\n",
            "before ready to have a 8urious conclusion of goodness to be a\n",
            "man who xarm out of the first thing of the signal to have a\n",
            "considerable sum of (our 9nd of the signal which was a .ind\n",
            "some of the bridegroom, which was a delicate painful expenses which he\n",
            "had to commence the xiusing gentlemen at the door of the world. it was a\n",
            "problem which was a man who had been read in the 0eanthere so that the\n",
            "facts was not yet to be 30 pounds at once to a zeath, many with his\n",
            "description and the  & fellow with the street, and he was both\n",
            "difficult to see what had been upon to question and saw the signature\n",
            "of them were not really very really the 'cooee!' and the ètall 1000 pounds at the\n",
            "sight of the matter.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "temperature = 0.02857142857142857\n",
            "ice which had been\n",
            "laid upon the words of the dead little morning and was still\n",
            "deeply attending the coroner and the train to the coroner which he had sat\n",
            "down to the things of the united strong âto me. i suppose that i have\n",
            "been exceptionally fear to him as to what is the best possible between the\n",
            "22nd the éary and marriage, and i have no doubt that he would be\n",
            "absolutely \n",
            "in the man who has been a considerable track of a effect of ?\"\n",
            "\n",
            "\"i am afraid that i have had the last man and should be able to see that the\n",
            "reason was (ord of the matter.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "temperature = 0.025\n",
            "ice which had been\n",
            "decovering to his head and looked at the neighbourhood.\n",
            "\n",
            "\"the man who was a man who has already had the matter of the\n",
            "!\" he shouted and strong which had been engaged as he had\n",
            "been always to be a small hair which was a fellow-state of the more\n",
            "conventing to me to be a single considerable sum of the man who\n",
            "had been worth and 0arried and should be able to ask you all the\n",
            "coroner's the street. the lady was able to see that he had told me at\n",
            "the time of the matter for the train to the man who had been of\n",
            "used by the matter.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "temperature = 0.022222222222222223\n",
            "ice which showed that\n",
            "her father was a little short room and a sharp face and his !ather was\n",
            "acting for her father were of her father was a signal to the strange\n",
            "entreating of the signal which was a very near heavy dead neck of the\n",
            "signal to 7need at the sight of the streets of the more than of\n",
            "the coroner and the first that the man was a little silence to the\n",
            "coroner and the paper which had been at the sight of the streets of\n",
            "the coroner's death. i was always with the weary singular chance of\n",
            "the coroner and the door.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "temperature = 0.02\n",
            "ice which had been\n",
            "had a considerable sum of considerable success. the coroner: when i\n",
            "saw that the matter was a professional points which he had been\n",
            "6arried, and the man who had 30 here a deadly state of stoke more. it is a\n",
            "very commonplace an excellent and a man who is not àir of the matter. i\n",
            "have no doubt that the matter should be happy to be a strong points of\n",
            "many minutes, and the man who is not so far as to the other side of the\n",
            "bedroom. he was always a country door of the police and 1000 pounds as\n",
            "to the result of the streets of (etterm of something close and\n",
            "streaked in the ground from and stronger to the signature of the streets of\n",
            "the more clean to the very man who had been already an action to\n",
            "him.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "temperature = 0.01\n",
            "ice which had been\n",
            "destroyed. he was a proforment to say that i had not been waiting for\n",
            "her than the signal which was a distinct of and of the matter to\n",
            "himself and the man who had been all over the sight of the\n",
            "streets of the signal to the coroner's things. there was no sign of\n",
            "the coroner and the bank of mine, and the man who had been sent on the\n",
            "conclusion of the streets of the coroner and the coroner and the last man,\n",
            "with a heavy garden clost to the street, and he was a little close\n",
            "at the door of the streets of the coroner and the last sign of his\n",
            "chair and struck his head and strode off to having her father,\n",
            "whose arrive brought of his hands in the corner of the coroner and the\n",
            "coroner and the coroner and the first that the man was a singular\n",
            "case of the signal to the coroner and the train to the signal\n",
            "with a heavy face of the coroner and the coroner and the\n",
            "coroner and the coroner and the sight of the streets of the\n",
            "contents in the coroner and the other of the signal with his father,\n",
            "and the colonel was a particularly clothes of the morning to his father, and\n",
            "the colonel was a particularly clothes of the morning before i was absolutely\n",
            "cleared to the result of the coroner: which is a sign of a\n",
            "man who had been at the sight of the street, and i have no\n",
            "doubt that he would not be some constraint and search of\n",
            "the first and thin that i was absolutely surprised to him.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KMXIasqN_whT",
        "colab_type": "code",
        "colab": {},
        "outputId": "51179657-d8e1-4efc-89ca-9517aedd3508"
      },
      "cell_type": "code",
      "source": [
        "def sample_char(txt,alpha):\n",
        "    assert(len(txt) == seq_length)\n",
        "    pattern = [[0 for i in range(len(chars))] for j in range(seq_length)]\n",
        "    for i,c in enumerate(txt):\n",
        "        pattern[i][chars_to_int[c]] = 1\n",
        "    x = np.reshape(pattern, (1, len(pattern), len(chars)))\n",
        "    prediction = model.predict(x, verbose=0)[0]\n",
        "    prediction *= alpha\n",
        "    prediction -= max(prediction)\n",
        "    prediction = np.exp(prediction)\n",
        "    prediction /= sum(prediction) + 1e-6\n",
        "    index = np.argmax(np.random.multinomial(1,prediction,1))\n",
        "    return ints_to_char[index]\n",
        "\n",
        "def sample_word(txt,alpha):\n",
        "    txt = \" \"*(seq_length - len(txt)) + txt\n",
        "    prv = None\n",
        "    w = ''\n",
        "    while (prv is None or prv.isalnum() or len(w) < 2) and len(w) < 15: \n",
        "        c = sample_char(txt[-seq_length:],alpha)\n",
        "        w += c\n",
        "        txt += c\n",
        "        prv = c\n",
        "    return w\n",
        "\n",
        "seed = \"what is my name ?\".lower()\n",
        "txt = seed\n",
        "word_cnt = 100\n",
        "g = \"\"\n",
        "for i in range(word_cnt):\n",
        "    w = sample_word(txt[-seq_length:],35)\n",
        "    txt += w\n",
        "    g += w\n",
        "print('seed:',seed)\n",
        "print('tot txt:')\n",
        "print(txt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed: what is my name ?\n",
            "tot txt:\n",
            "what is my name ?'\n",
            "\n",
            "\"'the coroner: i shall be able to ask you all the matter. it is a very\n",
            "new pare crime.\"\n",
            "\n",
            "\"i have the advice of the son of the interest.\"\n",
            "\n",
            "\"what do you think that i have had the matter?\"\n",
            "\n",
            "\"i shall be 30 pounds a year--that is your conour and the last sign of\n",
            "more so that i have àver been so a distinct of a 9ther and a xecture\n",
            "of the man who had been at the sight of the streets of the signal\n",
            "with a note of a great \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}